% Todo:

\documentclass[12pt]{article}
\usepackage{xeCJK}
\usepackage{fontspec}
%\setCJKmainfont{SimSun}
\setCJKmainfont[BoldFont=SimHei,ItalicFont=KaiTi]{SimSun}
\setCJKsansfont{SimHei}
\setCJKmonofont{SimKai}
\setmainfont{Arial}

\usepackage{cite}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsfonts}
% \usepackage{amsmath}	% for \tag
\usepackage{amssymb}	% for \multimap
% \usepackage{stmaryrd}
\usepackage{color}
%\usepackage[square,numbers]{natbib}
%\nocopyright
%\usepackage{latexsym,amsmath,amssymb,graphicx,hyperref}
%\usepackage{times} % gives you a bit more space if needed

% \definecolor{LogicColor}{rgb}{0.4,0.1,0.4}  % Magenta
\definecolor{LogicColor}{rgb}{0,0,0}	% for black-and-white paper

\newcommand{\english}[1]{\rmfamily \textit{``#1''}\rmfamily}
\newcommand{\formula}[1]{\ttfamily#1\rmfamily}

\newcommand{\df}{f} %probability density function
\newcommand{\dfo}{f1} %other probability density function
\newcommand{\fv}{x} %fuzzy variable
\newcommand{\tab}{\hspace*{1cm}}
\newcommand{\zand}{\; \tilde{\wedge} \;}
\newcommand{\zor}{\; \tilde{\vee} \;}
\newcommand{\PimpL}{\leftarrowtriangle}
\newcommand{\com}{\multimap}
\newcommand{\comL}{\circ \hspace{-0.4em} - \,}
\newcommand{\mul}{}
\newcommand{\loves}{loves }
\newcommand{\heart}{\, \heartsuit \,}

\setlength{\oddsidemargin}{1cm}
\setlength{\evensidemargin}{1cm}
\setlength{\textwidth}{14cm}

\title{Genifer 3.0 白皮书}
\author{YKY (\textit{甄景贤})}
% \institute{}

\begin{document}

\maketitle
\setlength{\parindent}{0em}
\setlength{\parskip}{1.5ex plus0.5ex minus1.2ex}

\vspace{0.5cm}
\tab\tab \parbox{11cm}{\textit{我是个发烧友，但不是疯子，因为我对於如何建构飞机有些心得。 我希望分享我所知的一切，然后，如可能的话，出一分力去帮助那将来会达到最终成功的人。}}
\vspace{-0.5cm}
\begin{flushright}
-- Wilbur Wright
\end{flushright}

\begin{abstract}
介绍通用人工智能\  Genifer 的理论。
\end{abstract}

\section{Genifer 3.0 理论}

\subsection{逻辑}

\subsection{动作}

我们有了动作 但不知道怎样指向\textbf{对象}。 其中一个可能的办法是 用 label 标签上次的答案；  或者作用於所有答案（但这是不自然的？） 

这引申到注意力的问题。  或者 Genifer 永远只是 focus 在注意力的前沿？

还有个问题就是：答案并不一定是唯一的。 所以需要一个方法去把 KB 的答案 掟回到 register 里。  

但那又引申到 working memory 和 KB 的区别。  或者 attention 只是 derivation 的 time-decaying trace？  换句话说，那些可能的答案只有很少几个。  我们应该可以利用某些特徵提取他们。

最简单可能就是 -1 和「没有」的分别。  如何区别「有」和「没有」呢？  可以指定答案的 class，例如「广东话字词」。

\subsection{学习}

学习的目的是寻找一组逻辑 formulas 去解释这世界。  所谓解释即推导。

学习的方法是 inductive learning，即由事实诱导出法则 (induce rules from facts)。 Rules 就是逻辑範式。

Induction 需要的是一个 general-to-specific order。  传统逻辑中这个序由两方面达成：
\begin{enumerate}
\item 某个 concept 比另一个 concept 更一般，例如： 动物／狗
\item conjunctions 的增加，例如： 戴眼镜 $\wedge$ 长头发
\end{enumerate}

压缩的方法必须是 ``semantic distance preserving''，意即： 在语义空间中相似的点被压缩到相邻的逻辑範式。

Gradient descent 的原理是我们必须知道 $\frac{\partial\mathcal{E}}{\partial\mathbf{r}}$ 的值，其中 $\mathcal{E}$ 是误差，$\mathbf{r}$ 是法则空间中的座标。

误差 $\mathcal{E}$ 由下式给出：
$$ \mathcal{E} = || R^\infty(\mathcal{F}) - \mathcal{F}^* || $$ 
$\mathcal{F}$ 是已知事实，$\mathcal{F}^*$ 是新的要学习的事实，$R$ 是所有法则，$r \in R$。

问题似乎是： 法则的诱导似乎不能单是基於语法。 概念阶层的诱导是基於： Liebniz 和 $a R b$。

Liebniz extensionality:
\begin{eqnarray}
xZ \rightarrow yZ \Leftrightarrow x \supset y \\
Zx \rightarrow Zy \Leftrightarrow x \supset y
\end{eqnarray}

There are 2 ways to generalize a logic formula:
\begin{enumerate}
\item adding \textbf{conjunctions}
\item using concepts that admit \textbf{substitutions}
\end{enumerate}

The relation of subsumption is \textit{intrinsic} to the logic.  

\section{徵求合作者}

例如，我去过 香港科技大學 找人，但那研究生说他们簽了合约，规定不准幫外面工作（大概这是大学控制知识产权的一种措施）。

\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Notation} & \textbf{Meaning} & \textbf{Example } \\
\hline
$A \supset B$ & concept A is a superset of concept B &
$animals \supset cats$ \\
& &  \english{cats are animals} \\
\hline
$A \ni B$        & concept A contains an element concept B &
$a \circ bird \supset tweety$ \\
& & \english{Tweety is a bird} \\
\hline
$A \rightarrow B$ & proposition A entails proposition B &
$bird \, X \supset can \, fly \, X$ \\
& & \english{If X is a bird X can fly} \\
\hline
\end{tabular}

\begin{figure}
\centering
\includegraphics[scale=0.8]{ontology-relations-relations.pdf}
\caption{Left: relations between ontological data.  Right: a random example of dendrogram.}
\label{fig:ontology-relations-relations}
\end{figure}

\section*{Appendix: XXXX}

\section*{Acknowledgments}

I am heavily indebted to Pei Wang \cite{Wang2006} \cite{Wang2013} and Ben Goertzel \cite{Goertzel2011} for their seminal contributions to AGI.  To Abram Demski and Russell Wallace -- we have spent years exploring many ideas in logic.  Also thanks to Matt Mahoney, Jeff Thompson for discussions of the draft.  William Taysom, Seh, and Joseph Cheung helped implement the code.

\bibliographystyle{plain} % or number or aaai ...
\bibliography{AGI-book}

\onecolumn

% Bigger figures

\end{document}
